<clickhouse>
    <listen_host>0.0.0.0</listen_host>

    <!-- Global file cache (serves S3 reads) -->
    <filesystem_cache>
        <path>/var/lib/clickhouse/file_cache</path>
        <max_size>8Gi</max_size> <!-- leave ~2GB for parts/metadata -->
        <enable_cache_hits_threshold>0</enable_cache_hits_threshold>
    </filesystem_cache>

    <storage_configuration>
        <disks>
            <local_data_disk>
                <type>local</type>
                <path>/var/lib/clickhouse/data/</path>
                <keep_free_space_bytes>2Gi</keep_free_space_bytes> <!-- always leave 2GB free -->
                <reserved_space_bytes>10Gi</reserved_space_bytes>   <!-- ClickHouse wonâ€™t exceed ~10GB here -->
            </local_data_disk>

            <s3_disk>
                <type>s3</type>
                <endpoint>https://nbg1.your-objectstorage.com/rybbit/clickhouse/</endpoint>
                <access_key_id from_env="S3_ACCESS_KEY"/>
                <secret_access_key from_env="S3_SECRET_KEY"/>
                <region from_env="S3_REGION"/>
                <use_virtual_addressing>true</use_virtual_addressing>
                <metadata_path>/var/lib/clickhouse/disks/s3_disk_metadata/</metadata_path>

                <!-- Object storage tuning -->
                <skip_access_check>true</skip_access_check>
                <max_concurrent_upload_operations>16</max_concurrent_upload_operations>
                <max_download_threads>32</max_download_threads>

                <!-- If your CH version supports these, they help a lot -->
                <cache_enabled>true</cache_enabled>
                <max_cache_size>8Gi</max_cache_size>
                <max_file_segment_size>32Mi</max_file_segment_size>
            </s3_disk>
        </disks>

        <policies>
            <!-- Use this one -->
            <tiered_s3_policy>
                <volumes>
                    <hot>
                        <disk>local_data_disk</disk>
                        <!-- keep merges reasonable -->
                        <max_data_part_size_bytes>1073741824</max_data_part_size_bytes>
                        <move_factor>0.95</move_factor>
                    </hot>
                    <cold>
                        <disk>s3_disk</disk>
                    </cold>
                </volumes>
            </tiered_s3_policy>

            <!-- Keep for special cases; not the default -->
            <s3_policy>
                <volumes>
                    <default>
                        <disk>s3_disk</disk>
                    </default>
                </volumes>
            </s3_policy>
        </policies>
    </storage_configuration>

    <profiles>
        <default>
            <storage_policy>tiered_s3_policy</storage_policy>

            <!-- Ingest speed-ups -->
            <async_insert>1</async_insert>
            <wait_for_async_insert>0</wait_for_async_insert>
            <max_insert_block_size>1048576</max_insert_block_size>  <!-- up to 1M rows -->
            <input_format_parallel_parsing>1</input_format_parallel_parsing>
            <use_filesystem_cache>1</use_filesystem_cache>

            <!-- Background pools -->
            <max_part_loading_threads>8</max_part_loading_threads>
            <background_pool_size>16</background_pool_size>
            <background_move_pool_size>8</background_move_pool_size>
            <background_fetches_pool_size>16</background_fetches_pool_size>

            <!-- S3 resilience -->
            <s3_max_single_read_retries>5</s3_max_single_read_retries>
            <s3_enable_parallel_part_upload>1</s3_enable_parallel_part_upload>
            <s3_max_inflight_requests>64</s3_max_inflight_requests>
        </default>
    </profiles>
</clickhouse>
